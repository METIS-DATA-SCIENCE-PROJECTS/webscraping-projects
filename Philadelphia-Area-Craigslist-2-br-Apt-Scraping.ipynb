{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc530ba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped successfully!\n",
      "Page 2 scraped successfully!\n",
      "Page 3 scraped successfully!\n",
      "Page 4 scraped successfully!\n",
      "Page 5 scraped successfully!\n",
      "Page 6 scraped successfully!\n",
      "Page 7 scraped successfully!\n",
      "Page 8 scraped successfully!\n",
      "Page 9 scraped successfully!\n",
      "Page 10 scraped successfully!\n",
      "Page 11 scraped successfully!\n",
      "Page 12 scraped successfully!\n",
      "Page 13 scraped successfully!\n",
      "Page 14 scraped successfully!\n",
      "Page 15 scraped successfully!\n",
      "Page 16 scraped successfully!\n",
      "Page 17 scraped successfully!\n",
      "\n",
      "\n",
      "Scrape complete!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2193 entries, 0 to 2192\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   posted           2193 non-null   object \n",
      " 1   neighborhood     2193 non-null   object \n",
      " 2   post title       2193 non-null   object \n",
      " 3   number bedrooms  2193 non-null   object \n",
      " 4   sqft             1666 non-null   float64\n",
      " 5   URL              2193 non-null   object \n",
      " 6   price            2193 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 120.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from requests import get \n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import re\n",
    "from random import randint \n",
    "from warnings import warn\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# request the contents of the page we're scraping\n",
    "results = get('https://philadelphia.craigslist.org/d/apartments-housing-for-rent/search/apa?availabilityMode=0&bundleDuplicates=1&hasPic=1&laundry=1&max_price=2050&min_bedrooms=2')\n",
    "\n",
    "# make the content we grabbed easy to read\n",
    "html_soup = BeautifulSoup(results.text, 'html.parser')\n",
    "\n",
    "# get the macro-container containing the posts we want\n",
    "post = html_soup.find_all('li', class_= 'result-row')\n",
    "\n",
    "\n",
    "# find the total number of posts to find the limit of the pagination\n",
    "find_total = html_soup.find('div', class_= 'search-legend')\n",
    "\n",
    "# grab the total count of posts \n",
    "total_posts = int(find_total.find('span', class_='totalcount').text) \n",
    "\n",
    "# vary the value of the page parameters\n",
    "pages = np.arange(0, total_posts+1, 120)\n",
    "\n",
    "# count tracker for number of iterations\n",
    "iterations = 0\n",
    "\n",
    "# initialize empty lists where we'll store our date \n",
    "post_times = []\n",
    "post_neighborhoods = []\n",
    "post_titles = []\n",
    "post_bedrooms = []\n",
    "post_sqft = []\n",
    "post_links = []\n",
    "post_prices = []\n",
    "\n",
    "\n",
    "# create for loop\n",
    "for page in pages:\n",
    "    \n",
    "    # get request\n",
    "    response = get(\"https://philadelphia.craigslist.org/d/apartments-housing-for-rent/search/apa?\" \n",
    "                   + \"s=\" # parameter for defining the page number \n",
    "                   + str(page) # page number in the pages array \n",
    "                   + \"&availabilityMode=0\"\n",
    "                   +\"&bundleDuplicates=1\"\n",
    "                   + \"&hasPic=1\"\n",
    "                   + \"&laundry=1\"\n",
    "                   +\"&max_price=2050\"\n",
    "                   +\"&min_bedrooms=2\"\n",
    "                  )\n",
    "    \n",
    "    # control the crawl rate \n",
    "    sleep(randint(1,10))\n",
    "    \n",
    "    # throw warning for status codes that are not 200\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "        \n",
    "    # define the html text\n",
    "    html = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # define the posts\n",
    "    posts = html_soup.find_all('li', class_= 'result-row')\n",
    "   \n",
    "   # extract data item-wise\n",
    "    for post in posts:\n",
    "\n",
    "        # if we aren't missing the neighborhood information\n",
    "        if post.find('span', class_ = 'result-hood') is not None:\n",
    "\n",
    "            # date\n",
    "            post_datetime = post.find('time', class_= 'result-date')['datetime']\n",
    "            post_times.append(post_datetime)\n",
    "\n",
    "            # neighborhoods\n",
    "            post_hoods = post.find('span', class_= 'result-hood').text\n",
    "            post_neighborhoods.append(post_hoods)\n",
    "\n",
    "            # title \n",
    "            post_title = post.find('a', class_='result-title hdrlnk')\n",
    "            post_title_text = post_title.text\n",
    "            post_titles.append(post_title_text)\n",
    "\n",
    "            # link\n",
    "            post_link = post_title['href']\n",
    "            post_links.append(post_link)\n",
    "            \n",
    "            # removes the \\n whitespace from each side, removes the currency symbol, and turns it into an int\n",
    "            post_price = int(float(post.a.text.strip().replace(\"$\", \"\").replace(\",\",\"\")))\n",
    "            post_prices.append(post_price)\n",
    "            # if the number of bedrooms OR sqft aren't missing \n",
    "            if post.find('span', class_ = 'housing') is not None:\n",
    "                \n",
    "                # if the first element is accidentally square footage\n",
    "                if 'ft' in post.find('span', class_ = 'housing').text.split()[0]:\n",
    "                    \n",
    "                    # make bedroom NaN\n",
    "                    bedroom_count = np.nan\n",
    "                    post_bedrooms.append(bedroom_count)\n",
    "                    \n",
    "                    # make sqft the first element\n",
    "                    sqft = int(post.find('span', class_ = 'housing').text.split()[0][:-3])\n",
    "                    post_sqft.append(sqft)\n",
    "                    \n",
    "                # if the length of the housing details element is more than 2\n",
    "                elif len(post.find('span', class_ = 'housing').text.split()) > 2:\n",
    "                    \n",
    "                    # therefore element 0 will be bedroom count\n",
    "                    bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
    "                    post_bedrooms.append(bedroom_count)\n",
    "                    \n",
    "                    # and sqft will be number 3, so set these here and append\n",
    "                    sqft = int(post.find('span', class_ = 'housing').text.split()[2][:-3])\n",
    "                    post_sqft.append(sqft)\n",
    "                    \n",
    "                # if there is num bedrooms but no sqft\n",
    "                elif len(post.find('span', class_ = 'housing').text.split()) == 2:\n",
    "                    \n",
    "                    # therefore element 0 will be bedroom count\n",
    "                    bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
    "                    post_bedrooms.append(bedroom_count)\n",
    "                    \n",
    "                    # and sqft will be number 3, so set these here and append\n",
    "                    sqft = np.nan\n",
    "                    post_sqft.append(sqft)                    \n",
    "                \n",
    "                else:\n",
    "                    bedroom_count = np.nan\n",
    "                    post_bedrooms.append(bedroom_count)\n",
    "                \n",
    "                    sqft = np.nan\n",
    "                    post_sqft.append(sqft)\n",
    "            # if none of those conditions catch, make bedroom NaN \n",
    "            else:\n",
    "                bedroom_count = np.nan\n",
    "                post_bedrooms.append(bedroom_count)\n",
    "                \n",
    "                sqft = np.nan\n",
    "                post_sqft.append(sqft)\n",
    "                \n",
    "    iterations += 1\n",
    "      \n",
    "    print(\"Page \" + str(iterations) + \" scraped successfully!\")\n",
    "\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Scrape complete!\")\n",
    "\n",
    "philly_apts = pd.DataFrame({'posted': post_times,\n",
    "                       'neighborhood': post_neighborhoods,\n",
    "                       'post title': post_titles,\n",
    "                       'number bedrooms': post_bedrooms,\n",
    "                        'sqft': post_sqft,\n",
    "                        'URL': post_links,\n",
    "                       'price': post_prices})\n",
    "\n",
    "print(philly_apts.info())\n",
    "philly_apts\n",
    "\n",
    "# to move all the scraped data to a CSV file\n",
    "philly_apts.to_csv('philly_apts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84255118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posted</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>post title</th>\n",
       "      <th>number bedrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>URL</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-08 20:54</td>\n",
       "      <td>(East Kensington  )</td>\n",
       "      <td>Newly Built! Fabulous 2BD with Central A/C &amp; S...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-08 20:48</td>\n",
       "      <td>(Art Museum  )</td>\n",
       "      <td>Pet Friendly! Terrific 2BD with HW Flooring - ...</td>\n",
       "      <td>2</td>\n",
       "      <td>988.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-08 20:30</td>\n",
       "      <td>(Brewerytown  )</td>\n",
       "      <td>Large 2BD in Brewerytown with Private Entrance...</td>\n",
       "      <td>2</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-08 20:21</td>\n",
       "      <td>(West Philly  )</td>\n",
       "      <td>Very cute 2bdrm 1bth apt at 50th and Baltimore</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-08 20:14</td>\n",
       "      <td>(Temple Girard Art Museum Francisville Brewer...</td>\n",
       "      <td>*Spacious Bi-Level Apartment Available Updated...</td>\n",
       "      <td>2</td>\n",
       "      <td>950.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2021-12-08 07:36</td>\n",
       "      <td>(West Oak Lane  )</td>\n",
       "      <td>UPDATED 3 BEDROOMS AND 1.5 BATHS HOME LOCATED ...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2021-12-08 07:36</td>\n",
       "      <td>(TEMPLE UNIVERSITY  )</td>\n",
       "      <td>NEWLY RENOVATED 2 BD / 1.5 BA MINUTES AWAY FRO...</td>\n",
       "      <td>2</td>\n",
       "      <td>950.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2021-12-08 07:36</td>\n",
       "      <td>(OGONTZ  )</td>\n",
       "      <td>UPDATED 2 BEDROOMS / 1 BATH APARTMENT AVAILABL...</td>\n",
       "      <td>2</td>\n",
       "      <td>800.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2021-12-08 07:36</td>\n",
       "      <td>(OGONTZ  )</td>\n",
       "      <td>UPDATED 2 BEDROOMS / 1 BATH APARTMENT AVAILABL...</td>\n",
       "      <td>2</td>\n",
       "      <td>800.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2021-12-08 07:36</td>\n",
       "      <td>(University City, Upenn, PENN, Drexel  )</td>\n",
       "      <td>AMAZING VALUE! SPACIOUS 2 BEDROOMS &amp; 1 BATH AP...</td>\n",
       "      <td>2</td>\n",
       "      <td>950.0</td>\n",
       "      <td>https://philadelphia.craigslist.org/apa/d/phil...</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2193 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                posted                                       neighborhood  \\\n",
       "0     2021-12-08 20:54                                (East Kensington  )   \n",
       "1     2021-12-08 20:48                                     (Art Museum  )   \n",
       "2     2021-12-08 20:30                                    (Brewerytown  )   \n",
       "3     2021-12-08 20:21                                    (West Philly  )   \n",
       "4     2021-12-08 20:14   (Temple Girard Art Museum Francisville Brewer...   \n",
       "...                ...                                                ...   \n",
       "2188  2021-12-08 07:36                                  (West Oak Lane  )   \n",
       "2189  2021-12-08 07:36                              (TEMPLE UNIVERSITY  )   \n",
       "2190  2021-12-08 07:36                                         (OGONTZ  )   \n",
       "2191  2021-12-08 07:36                                         (OGONTZ  )   \n",
       "2192  2021-12-08 07:36           (University City, Upenn, PENN, Drexel  )   \n",
       "\n",
       "                                             post title number bedrooms  \\\n",
       "0     Newly Built! Fabulous 2BD with Central A/C & S...               2   \n",
       "1     Pet Friendly! Terrific 2BD with HW Flooring - ...               2   \n",
       "2     Large 2BD in Brewerytown with Private Entrance...               2   \n",
       "3        Very cute 2bdrm 1bth apt at 50th and Baltimore               2   \n",
       "4     *Spacious Bi-Level Apartment Available Updated...               2   \n",
       "...                                                 ...             ...   \n",
       "2188  UPDATED 3 BEDROOMS AND 1.5 BATHS HOME LOCATED ...               3   \n",
       "2189  NEWLY RENOVATED 2 BD / 1.5 BA MINUTES AWAY FRO...               2   \n",
       "2190  UPDATED 2 BEDROOMS / 1 BATH APARTMENT AVAILABL...               2   \n",
       "2191  UPDATED 2 BEDROOMS / 1 BATH APARTMENT AVAILABL...               2   \n",
       "2192  AMAZING VALUE! SPACIOUS 2 BEDROOMS & 1 BATH AP...               2   \n",
       "\n",
       "        sqft                                                URL  price  \n",
       "0        NaN  https://philadelphia.craigslist.org/apa/d/phil...   1595  \n",
       "1      988.0  https://philadelphia.craigslist.org/apa/d/phil...   2015  \n",
       "2     1240.0  https://philadelphia.craigslist.org/apa/d/phil...   1995  \n",
       "3        NaN  https://philadelphia.craigslist.org/apa/d/phil...   1600  \n",
       "4      950.0  https://philadelphia.craigslist.org/apa/d/phil...   1475  \n",
       "...      ...                                                ...    ...  \n",
       "2188     NaN  https://philadelphia.craigslist.org/apa/d/phil...   1600  \n",
       "2189   950.0  https://philadelphia.craigslist.org/apa/d/phil...   1000  \n",
       "2190   800.0  https://philadelphia.craigslist.org/apa/d/phil...   1100  \n",
       "2191   800.0  https://philadelphia.craigslist.org/apa/d/phil...   1100  \n",
       "2192   950.0  https://philadelphia.craigslist.org/apa/d/phil...   1350  \n",
       "\n",
       "[2193 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philly_apts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96cee4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philly_apts['post title'].duplicated().sum()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
